{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aacf2abf",
      "metadata": {},
      "source": [
        "# BinSketch Algorithm Experiments\n",
        "\n",
        "This notebook runs experiments to evaluate the accuracy of similarity estimation algorithms (BinSketch, SimHash, MinHash) across different compression lengths.\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. **Setup**: Download and convert datasets (cells below)\n",
        "2. **Configure**: Set experiment parameters (thresholds, dataset, algorithms)\n",
        "3. **Run**: Execute experiment cells that call `main.py`\n",
        "\n",
        "The `main.py` script handles:\n",
        "- Loading binary matrices\n",
        "- Computing ground truth similarities\n",
        "- Running algorithms with different compression lengths\n",
        "- Generating accuracy plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "831f9bf5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive D is New Volume\n",
            " Volume Serial Number is 6085-9B4A\n",
            "\n",
            " Directory of d:\\hcmus\\introduction-to-algorithm-complexity-and-analysis\\binsketch-algorithm\n",
            "\n",
            "09-Jan-26  08:50 AM    <DIR>          .\n",
            "08-Jan-26  08:37 PM    <DIR>          ..\n",
            "08-Jan-26  11:56 PM                75 .gitignore\n",
            "09-Jan-26  12:43 AM    <DIR>          .venv\n",
            "09-Jan-26  12:51 AM            64,330 bin_sketch.ipynb\n",
            "09-Jan-26  12:07 AM             7,903 convert.py\n",
            "08-Jan-26  11:57 PM             1,673 download_dataset.py\n",
            "08-Jan-26  03:40 PM                 0 main.py\n",
            "09-Jan-26  12:35 AM                25 README.md\n",
            "09-Jan-26  12:51 AM                51 requirements.txt\n",
            "09-Jan-26  12:44 AM    <DIR>          src\n",
            "               7 File(s)         74,057 bytes\n",
            "               4 Dir(s)  473,662,222,336 bytes free\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc99a7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "DRIVE_URL = 'https://drive.google.com/drive/folders/1ARBY9cIGj_jigi5Y88CtUy-GMj2clrXj'\n",
        "RAW_DATA_PATH = './raw'\n",
        "PROCESSED_DATA_PATH = './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a5e1dc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa49657",
      "metadata": {},
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d2c348",
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_dataset(drive_url, target_folder):\n",
        "    print(f\"Processing: {drive_url}\")\n",
        "    \n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "\n",
        "    if \"drive/folders\" in drive_url or \"folder\" in drive_url:\n",
        "        print(\"Downloading individual files directly...\")\n",
        "        gdown.download_folder(drive_url, output=target_folder, quiet=False, use_cookies=False)\n",
        "        print(f\"\\n[SUCCESS] Folder contents downloaded to: {target_folder}\")\n",
        "    else:\n",
        "        print(\"\\n[INFO] Detected a Drive FILE link.\")\n",
        "        zip_path = os.path.join(target_folder, \"temp_dataset.zip\")\n",
        "        output = gdown.download(drive_url, zip_path, quiet=False, fuzzy=True)\n",
        "        \n",
        "        if not output:\n",
        "            print(\"[ERROR] Download failed.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nUnzipping {output}...\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "                zip_ref.extractall(target_folder)\n",
        "            print(f\"[SUCCESS] Extracted to: {target_folder}\")\n",
        "            \n",
        "            # Clean up the zip file\n",
        "            os.remove(output)\n",
        "            \n",
        "        except zipfile.BadZipFile:\n",
        "            print(\"[ERROR] The downloaded file was not a valid zip file.\")\n",
        "            print(\"Check if the file on Drive is actually a .zip archive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2e619d",
      "metadata": {},
      "outputs": [],
      "source": [
        "download_dataset(DRIVE_URL, RAW_DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d7c5666",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python convert.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0249f8b3",
      "metadata": {},
      "source": [
        "### Experiment 1: Accuracy of Estimation\n",
        "\n",
        "Run experiments to evaluate the accuracy of similarity estimation across different compression lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d41273",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "THRESHOLD = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
        "threshold_str = \" \".join(map(str, THRESHOLD))\n",
        "\n",
        "# Available datasets: bbc, enron, kos, nytimes\n",
        "DATASET = 'enron'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2cbe46",
      "metadata": {},
      "source": [
        "#### Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b1d54e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment 1: Cosine Similarity\n",
        "data_path = f'./data/{DATASET}_binary.npy'\n",
        "\n",
        "!python main.py --data_path {data_path} --algo BinSketch SimHash MinHash --metric cosine_similarity --threshold {threshold_str}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7faa4b",
      "metadata": {},
      "source": [
        "### Experiment 2: Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf1cf06",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for Ranking Experiment\n",
        "RANKING_THRESHOLD = [.1, .2, .5, .6, .8, .85, .9, .95]\n",
        "ranking_threshold_str = \" \".join(map(str, RANKING_THRESHOLD))\n",
        "\n",
        "# Run ranking experiment\n",
        "data_path = f'./data/{DATASET}_binary.npy'\n",
        "\n",
        "!python main.py --data_path {data_path} --algo BinSketch SimHash MinHash --metric cosine_similarity --threshold {ranking_threshold_str}"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
